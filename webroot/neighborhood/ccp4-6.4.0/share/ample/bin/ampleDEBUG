#!/usr/bin/env python

#
#  Version 0.1  
#  no speed buffs, no extra functionality, no optimisation
#  Basic Pipeline
#  for multi core desktops, not clusters

# issues:
# 1) if this script is killed, the rosetta will continue
# 2) Theseus can hang, this is killed after a timeout 
# 3) is clustered by all atom RMSD to make fine clusters (option to cluster by CA only i included)
# 4) ASU content is the number of search models placed by MrBUMP. -- need to set this manually

import re
import os, glob
import sys
import subprocess
import shlex
import string
import time
import operator
import argparse
import random
from multiprocessing import Process, Queue, JoinableQueue, Pool, Value, Array
import pickle
import copy
import clusterize
import shutil

from add_sidechains_SCWRL import *
import cluster_entropy, truncateedit, truncateedit_MAX
import SCWRL_edit, Final_display_results

import run_mr_bump_shelx_parallel
import fasta_parser
import run_spicker
###############

#-------------------------------------------
#get command line options
#-------------------------------------------

parser = argparse.ArgumentParser(description='Structure solution by abinitio modeling', prefix_chars="-")

parser.add_argument('-ROSETTA', metavar='ROSETTA_path', type=str, nargs=1,
                   help='path for Rosetta AbinitioRelax')

parser.add_argument('-RDB', metavar='ROSETTA_database', type=str, nargs=1,
                   help='path for Rosetta database')

parser.add_argument('-fragsexe', metavar='path to make_fragments.pl', type=str, nargs=1,
                   help='location of make_fragments.pl')

parser.add_argument('-Rosetta_cluster', metavar='path to Rosettas cluster', type=str, nargs=1,
                   help='location of rosetta cluster')


parser.add_argument('-fasta', metavar='fasta_file', type=str, nargs=1,
                   help='protein fasta file. (required)')

parser.add_argument('-name', metavar='priotein name', type=str, nargs=1,
                   help='name of protien in the format ABCD ')


parser.add_argument('-NProc', metavar='NoProcessors', type=int, nargs=1,
                   help='number of processers (default 1)')


parser.add_argument('-RunDir', metavar='run_directory', type=str, nargs=1,
                   help='directory to put files (default current dir)')



parser.add_argument('-SCWRL', metavar='path to scwrl', type=str, nargs=1,
                   help='pathway to SCWRL exe')



parser.add_argument('-LGA', metavar='path_to_LGA dir', type=str, nargs=1,
                   help='pathway to LGA folder (not the exe) will use the \'lga\' executable')


parser.add_argument('-MAX', metavar='Maxcluster exe', type=str, nargs=1,
                   help='Maxcluster exe')


parser.add_argument('-THESEUS', metavar='Theseus exe (required)', type=str, nargs=1,
                   help='Theseus exe')

parser.add_argument('-MTZ', metavar='MTZ in', type=str, nargs=1,
                   help='MTZ in')


parser.add_argument('-MODELS', metavar='folder of decoys', type=str, nargs=1,
                   help='folder of decoys')

parser.add_argument('-MakeModels', metavar='Do the modelling', type=str, nargs=1,
                   help='run rosetta modeling, set to False to import pre-made models (required if making models locally default True)')

parser.add_argument('-ROSETTA_DIR', metavar='Rosetta_dir', type=str, nargs=1,
                   help='the Rosetta install directory')

## fragments

parser.add_argument('-make_frags', metavar='bool to make fragments', type=str, nargs=1,
                   help='Bool, True to make non homologous framents, False to import fragments')

parser.add_argument('-3mers', metavar='3mers', type=str, nargs=1,
                   help='path of imported 3mers')

parser.add_argument('-9mers', metavar='9mers', type=str, nargs=1,
                   help='path of imported 9mers') 

## FLAGS
parser.add_argument('-F', metavar='flag for F', type=str, nargs=1,
                   help='Flag for F')

parser.add_argument('-SIGF', metavar='flag for SIGF', type=str, nargs=1,
                   help='Flag for SIGF')

parser.add_argument('-FREE', metavar='flag for FREE', type=str, nargs=1,
                   help='Flag for FREE')

parser.add_argument('-CLUSTER', metavar='using a cluster', type=str, nargs=1,
                   help='will submit jobs to a cluster')

parser.add_argument('-ALLATOM', metavar='using a cluster', type=str, nargs=1,
                   help='will submit jobs to a cluster')

parser.add_argument('-SPICKER', metavar='spicker exe', type=str, nargs=1,
                   help='path and will use spicker as alternative')

parser.add_argument('-domain_all_chains_pdb', metavar='domain_all_chains_pdb', type=str, nargs=1,
                   help='fixed input to mr bump')

parser.add_argument('-domain_all_chain_fasta', metavar='domain_all_chain_fasta', type=str, nargs=1,
                   help='fasta for all ASU')

parser.add_argument('-domain_termini', metavar='termini', type=str, nargs=1,
                   help='distacne between termini for insert domains')


parser.add_argument('-NMODELS', metavar='no models', type=int, nargs=1,
                   help='number of models to make (1000)')


parser.add_argument('-CC', metavar='rad of gyration', type=str, nargs=1,
                   help='radius of gyration reweight ')

parser.add_argument('-ensembles', metavar='enembles', type=str, nargs=1,
                   help='path to ensembles')

parser.add_argument('-noClusters', metavar='no clus to sample', type=str, nargs=1,
                   help='number of clusters to sample')


parser.add_argument('-percent', metavar='no clus to sample', type=str, nargs=1,
                   help='percent interval for truncation')

parser.add_argument('-ASU', metavar='no in ASU', type=int, nargs=1,
                   help='no in ASU')


parser.add_argument('-FreeLunch', metavar='free lunch', type=int, nargs=1,
                   help='true to use free lunch, false to not use it')

parser.add_argument('-usehoms', metavar='nohoms rosetta flag', type=str, nargs=1,
                   help='True =use nhomologs, False= dont use them ')

parser.add_argument('-ImproveTemplate', metavar='improve template', type=str, nargs=1,
                   help='give a template to imrove - NMR, homolog ')



#convert args to dictionary
args = parser.parse_args()
print args


var_args = vars(args)


#Required commands:


if var_args['ROSETTA_DIR'] is None:
   ROSETTA_OVER_PATH = os.environ.get("ROSETTA_PATH")
if not var_args['ROSETTA_DIR'] is None:
   if var_args['ROSETTA_DIR'][0] != 'none': 
     ROSETTA_OVER_PATH = var_args['ROSETTA_DIR'][0]
   if var_args['ROSETTA_DIR'][0] == 'none':
     ROSETTA_OVER_PATH = os.environ.get("ROSETTA_PATH")     

if var_args['ROSETTA'] is None:
   ROSETTA_PATH = 'no_path_given'
if not var_args['ROSETTA'] is None: 
   ROSETTA_PATH = var_args['ROSETTA'][0]

if var_args['RDB'] is None:
   ROSETTA_DB = 'no_path_given'
if not var_args['RDB'] is None: 
   ROSETTA_DB = var_args['RDB'][0]


if var_args['fragsexe'] is None:
  Make_fragents_exe = ' '
if not var_args['fragsexe'] is None:
  Make_fragents_exe = var_args['fragsexe'][0] 

if var_args['Rosetta_cluster'] is None:
   ROSETTA_cluster = 'no_path_given'
if not var_args['Rosetta_cluster'] is None: 
   ROSETTA_cluster = var_args['Rosetta_cluster'][0]


if var_args['fasta'] is None:
    FASTA = 'no_fasta_given'
if not var_args['fasta'] is None:
    FASTA = var_args['fasta'][0] 

if var_args['name'] is None:
   PDB_code = 'ABCD'
if not var_args['name'] is None:
   PDB_code =var_args['name'][0]

if var_args['NProc'] is None:
   NProc = 1
if not var_args['NProc'] is None:
   NProc = var_args['NProc'][0]


if var_args['RunDir'] is None:
   RunDir = os.getcwd()
if not var_args['RunDir'] is None:
   RunDir = var_args['RunDir'][0]



if var_args['SCWRL'] is None:
  SCWRL = os.environ.get("SCWRL_EXE")
if not var_args['SCWRL'] is None:
 if var_args['SCWRL'][0] !='none':
  SCWRL =var_args['SCWRL'][0] 
 if var_args['SCWRL'][0] =='none':
  SCWRL = os.environ.get("SCWRL_EXE")

 

if var_args['LGA'] is None:
  LGA = os.environ.get("LGA_PATH")
if not var_args['LGA'] is None:
  if var_args['LGA'][0] != 'none':
    LGA =var_args['LGA'][0] 
  if var_args['LGA'][0] == 'none':
     LGA = os.environ.get("LGA_PATH")

if var_args['MAX'] is None:
  MAX = os.environ.get("MAX_EXE")
if not var_args['MAX'] is None:
  if var_args['MAX'][0] != 'none':
    MAX =var_args['MAX'][0]
  if var_args['MAX'][0] == 'none':
    LGA = os.environ.get("MAX_EXE")


if var_args['THESEUS'] is None:
   THESEUS = os.environ.get("THESEUS_EXE")
if not var_args['THESEUS'] is None:
  if var_args['THESEUS'][0] != 'none':
   THESEUS = var_args['THESEUS'][0]
  if var_args['THESEUS'][0] == 'none':
   THESEUS = os.environ.get("THESEUS_EXE")





print var_args['MTZ']
if var_args['MTZ'] is None:
   MTZ = 'none'
if not var_args['MTZ'] is None:
   MTZ = var_args['MTZ'][0]

IMPORTING_MODELS=False
if var_args['MODELS'] is None:
   MODELS_LOCATION = ''
if not var_args['MODELS'] is None:
   MODELS_LOCATION = var_args['MODELS'][0]
   IMPORTING_MODELS=True

MakeModels = True

if var_args['MakeModels'] is None:
   MakeModels = True
if not var_args['MakeModels'] is None:
   if var_args['MakeModels'][0] == 'False':
     MakeModels = False
     print '\nNOT Making Rosetta Models\n'
   if var_args['MakeModels'][0] == 'True':
     MakeModels = True
     print '\nMaking Rosetta Models\n'


###fragments


if var_args['make_frags'] is None:
   MakeFrags = True
if not var_args['make_frags'] is None:
   if var_args['make_frags'][0] == 'False':
     MakeFrags = False
     print '\nNOT Making Fragments\n'
   if var_args['make_frags'][0] == 'True':   
     MakeFrags = True
     print '\nMaking non homologusFragments\n'


if var_args['3mers'] is None:
   frags_3_mers = ''
if not var_args['3mers'] is None:
   frags_3_mers = var_args['3mers'][0]


if var_args['9mers'] is None:
   frags_9_mers = ''
if not var_args['9mers'] is None:
   frags_9_mers = var_args['9mers'][0]


if var_args['usehoms'] is None:
   nohoms = ' -nohoms '
if not var_args['usehoms'] is None:
  if "TRUE" in var_args['usehoms'][0].upper():
      nohoms = ' '
  elif "FALSE" in var_args['usehoms'][0].upper():
      nohoms = ' -nohoms '

##flags
if var_args['F'] is None:
   notused, flag_SIGF, flag_F , flag_FREE  = run_mr_bump_shelx_parallel.get_flags (MTZ)
if not var_args['F'] is None:
   flag_F = var_args['F'][0]
   

if var_args['SIGF'] is None:
   notused, flag_SIGF, flag_F , flag_FREE  = run_mr_bump_shelx_parallel.get_flags (MTZ)
if not var_args['SIGF'] is None:
   flag_SIGF = var_args['SIGF'][0]

if var_args['FREE'] is None:
   notused, flag_SIGF, flag_F , flag_FREE = run_mr_bump_shelx_parallel.get_flags (MTZ)
if not var_args['FREE'] is None:
   flag_FREE = var_args['FREE'][0]

print flag_F, flag_SIGF, flag_FREE

if var_args['CLUSTER'] is None:
   CLUSTER= False
else:
  if "TRUE" in var_args['CLUSTER'][0].upper():
     CLUSTER = True
  elif "FALSE" in var_args['CLUSTER'][0].upper():
     CLUSTER = False
  else:
     CLUSTER = False

if var_args['ALLATOM'] is None:
   ALLATOM= False
else:
  if "TRUE" in var_args['ALLATOM'][0].upper():
     ALLATOM = True
  elif "FALSE" in var_args['ALLATOM'][0].upper():
     ALLATOM = False
  else:
     ALLATOM = False

#----------missing domains

MISSING_DOMAINS = False

if var_args['domain_all_chains_pdb'] is None:
   domain_all_chains_pdb='none'
if not var_args['domain_all_chains_pdb'] is None:
    domain_all_chains_pdb= var_args['domain_all_chains_pdb'][0]
    MISSING_DOMAINS = True


if var_args['domain_all_chain_fasta'] is None:
   domain_all_chain_fasta='none'
if not var_args['domain_all_chain_fasta'] is None:
    domain_all_chain_fasta= var_args['domain_all_chain_fasta'][0]
    MISSING_DOMAINS = True


FIXED_INPUT = True


#-------------\missing domains

if var_args['NMODELS'] is None:
    NMODELS = 1000
if not var_args['NMODELS'] is None:
    NMODELS= var_args['NMODELS'][0]


if var_args['percent'] is None:
    percent = 5
    FIXED_INTERVALS = True
if not var_args['percent'] is None:
    percent= var_args['percent'][0]
    FIXED_INTERVALS = False


INSERT_DOMAIN=False
if var_args['domain_termini'] is None:
   
    domain_termini_distance=0
if not var_args['domain_termini'] is None:
    domain_termini_distance= var_args['domain_termini'][0]
    INSERT_DOMAIN=True


CCline=''
if var_args['CC'] is None:
    CCline = ''
if not var_args['CC'] is None:
  if "none" in var_args[''][0].upper():
    CCline= ''
  else:
    CCline= ' -rg_reweight 0 '


ENSEMBLE_import=False
if var_args['ensembles'] is None:
    ENSEMBLES=''
if not var_args['ensembles'] is None:
    ENSEMBLES= var_args['ensembles'][0]
    ENSEMBLE_import =True


USE_SPICKER=False
if var_args['SPICKER'] is None:
    USE_SPICKER=False
if not var_args['SPICKER'] is None:
    SPICKEREXE= var_args['SPICKER'][0]
    USE_SPICKER =True
    if not os.path.exists(SPICKEREXE):
      SPICKEREXE = os.environ.get("SPICKER_EXE")


noClusters=1
if var_args['noClusters'] is None:
    noClusters=1 
if not var_args['noClusters'] is None:
    noClusters= var_args['noClusters'][0]


noASU=''
if var_args['ASU'] is None:
    noASU = ''
if not var_args['ASU'] is None:
    noASU = 'NMASU '+ str(var_args['ASU'][0])


if var_args['ImproveTemplate'] is None:
    template = ''
    ImportTemplate =False
if not var_args['ImproveTemplate'] is None:
    template =  var_args['ImproveTemplate'][0]
    ImportTemplate =True


if var_args['FreeLunch'] is None:
    FreeLunch= True
if not var_args['FreeLunch'] is None:
    FreeLunch = var_args['FreeLunch'][0]



#--------------------------------------------
#give the run file to check
	#---------------------------------------------

Run_params = open(RunDir +'/Params_used', "w")
print var_args
for print_user in var_args:
 if var_args[print_user] is not None:
  print print_user +' : ' + str(var_args[print_user][0])

  Run_params.write(print_user +' : ' + str(var_args[print_user][0]) + '\n')
Run_params.close()

#---------------------------------------
#check for errors
#---------------------------------------

print 'Making a Run Directory  -checking for previous runs'
run_inc = 0
run_making_done = False
while run_making_done  == False:
 if not os.path.exists(RunDir + '/ROSETTA_MR_'+str(run_inc)):
  run_making_done = True
  os.mkdir(RunDir + '/ROSETTA_MR_'+str(run_inc))
 run_inc+=1
RunDir = RunDir + '/ROSETTA_MR_'+str(run_inc -1)



if MakeFrags==False:
 if MakeModels == True:
  if not os.path.exists(frags_3_mers):
    print 'Cant find 3mers'
    sys.exit()
  if not os.path.exists(frags_9_mers):
    print 'Cant find 9mers'
    sys.exit()


#check if got all the programs
if MakeModels == False:
 IMPORTING_MODELS = True

if MakeModels == True:
 if IMPORTING_MODELS == True:
  print MODELS_LOCATION
  print 'you have chosen to both import models and to make them, choose only one\nSet Make Models to \"True\" to make them, \"False\" to import them'
  sys.exit()

if IMPORTING_MODELS == True:
  if not os.path.exists(MODELS_LOCATION):
   print 'you have chosen to import models, but path does not exist, looking for ensembles'
   if not os.path.exists(ENSEMBLES):
    print 'you have chosen to import ensembles, but path does not exist'
    sys.exit()


 
 
if MakeModels == True:  #only need Rosetta if making models 

 if not os.path.exists(ROSETTA_OVER_PATH):
  ROSETTA_OVER_PATH = os.environ.get("ROSETTA_PATH")

 if os.path.exists(ROSETTA_OVER_PATH):
   ROSETTA_PATH               =ROSETTA_OVER_PATH+'/rosetta_source/bin/AbinitioRelax.linuxgccrelease'
   ROSETTA_cluster            =ROSETTA_OVER_PATH+'/rosetta_source/bin/cluster.linuxgccrelease'
   ROSETTA_DB                 =ROSETTA_OVER_PATH+'/rosetta_database'
   Make_fragents_exe          =ROSETTA_OVER_PATH+'/rosetta_fragments/nnmake/make_fragments.pl'

 if not os.path.exists(ROSETTA_PATH)  :
   print ' cant find Rosetta abinitio, check path names'
   print ROSETTA_PATH  
   sys.exit()

 if not os.path.exists(ROSETTA_cluster): 
   print ' cant find Rosetta cluster, check path names'
   sys.exit()
 if not os.path.exists(ROSETTA_DB) :
   print ' cant find Rosetta DB, check path names'
   sys.exit()
 if not os.path.exists(Make_fragents_exe):
   print ' cant find make fragments, check path names'
   sys.exit()


if not os.path.exists(FASTA):
    print 'You need to give the path for the fasta'
    sys.exit()

if not os.path.exists(RunDir):
    print 'You need to give a run directory'
    sys.exit()

if not os.path.exists(str(SCWRL)):
   SCWRL = os.environ.get("SCWRL_EXE")
   if not os.path.exists(str(SCWRL)): 
    print 'You need to give the path for SCWRL'
    sys.exit()

if not os.path.exists(str(MAX)):
   SCWRL = os.environ.get("MAX_EXE")
   if not os.path.exists(SCWRL): 
    print 'You need to give the path for SCWRL'
    sys.exit()

#if not os.path.exists(LGA):
#  LGA = os.environ.get("LGA_PATH")
#  if not os.path.exists(LGA):
#    print 'You need to give the path for LGA'
 #   sys.exit()

if not os.path.exists(THESEUS):
 THESEUS = os.environ.get("THESEUS_EXE")
 if not os.path.exists(THESEUS):
    print 'You need to give the path for THESEUS'
    sys.exit()

if len(PDB_code)>4 or len(PDB_code)<4:
   print 'name is the wrong length, use 4 chars eg ABCD, changing name'
   PDB_code='ABCD'

     
if len(PDB_code)==4: 
   PDB_code +='_'



if not os.path.exists(MTZ):
    print 'need mtz or no MR will be carried out'
    sys.exit()

if ImportTemplate:
   if not os.path.exists(template):
      print 'cant find template to improve'
      sys.exit()



print 'continuing Run'



#----------------------------
# params used
#---------------------------

#make a copy of params
#
Run_params = open(RunDir +'/Params_used', "w")
Run_params.write('input params\n')
print var_args
for print_user in var_args:
 if var_args[print_user] is not None:
  print print_user +' : ' + str(var_args[print_user][0])

  Run_params.write(print_user +' : ' + str(var_args[print_user][0]) + '\n')

Run_params.write('\nParams Used in this Run\n')
Run_params.write('\n---input---\nFasta '+FASTA+'\nRunDir '+RunDir+'\nMTZ '+MTZ+'\nname '+PDB_code+'\n')
Run_params.write('\n---fragments---\nMakeFrags '+str(MakeFrags)+'\n3mers '+frags_3_mers+'\n9mers '+frags_9_mers+'\n')
Run_params.write('\n---modelling---\nMakeModels '+str(MakeModels)+'\nROSETTA_PATH '+ROSETTA_PATH+'\n')
Run_params.write('ROSETTA_cluster '+ROSETTA_cluster+'\nROSETTA_DB '+ROSETTA_DB+'\nMake_fragents_exe '+Make_fragents_exe+'\n')
Run_params.write('\n---3rd party---\nSCWRL '+SCWRL+'\nTHESEUS '+THESEUS+'\nLGA '+LGA+'\n')
Run_params.write('\n---Missing Domain---\nall chains fasta '+domain_all_chain_fasta+'\nall chain pdb '+domain_all_chains_pdb+'\nMISSING DOMAINS='+str(MISSING_DOMAINS)+'\n')
Run_params.write('Is an Insert Domain '+str(INSERT_DOMAIN)+ ' termini distance '+ str(domain_termini_distance) +'\n')

Run_params.close()



#-----------------------------------
#Do The Modelling
#-----------------------------------


time_start=time.time()
RUNNING=open( RunDir +'/ROSETTA.log', "w")

print PDB_code
os.chdir(RunDir)
  
outfasta=os.path.join(RunDir, PDB_code+'_.fasta')
fasta_parser.parse_fasta(FASTA, outfasta)
FASTA=outfasta
#####make frags 

if MakeFrags == True:

  RUNNING.write('----- making fragments--------\n')
  RUNNING.flush()
  frags_dir = RunDir + '/frags'
  os.system('mkdir ' + frags_dir)
  print Make_fragents_exe + ' -rundir ' + frags_dir + ' -id ' + PDB_code + ' '+FASTA+ ' -nojufo -nosam -noprof  ' +nohoms 
  os.system(Make_fragents_exe + ' -rundir ' + frags_dir + ' -id ' + PDB_code + ' '+FASTA+ ' -nojufo -nosam -noprof '+ nohoms    ) 

  frags_3_mers = frags_dir + '/aa' +PDB_code+'03_05.200_v1_3'
  frags_9_mers = frags_dir + '/aa' +PDB_code+'09_05.200_v1_3'

  RUNNING.write('Fragments done\n3mers at: '+frags_3_mers+'\n9mers at: '+frags_9_mers+'\n\n')




###modeling
insert_Rosetta_command=''
if INSERT_DOMAIN==True:
    fas=open(FASTA)
    seq=''
    for line in fas:
     if not re.search('>', line):
      seq+=line.rstrip('\n')
    length=0
    for x in seq:
     if re.search('\w', x):
      length+=1


    print 'restricting termini distance',  domain_termini_distance
    constraints_file = os.path.join(RunDir, 'constraints')
    conin=open(constraints_file,"w")
    conin.write('AtomPair CA 1 CA '+str(length)+' GAUSSIANFUNC '+str(domain_termini_distance)+' 5.0 TAG')
    insert_Rosetta_command=' -constraints:cst_fa_file '+ constraints_file + ' -constraints:cst_file '+ constraints_file + ' '
     


RUNNING.write('----- making models--------\n')
RUNNING.flush()
DEBUG = False



if ImportTemplate ==True:
       CCline += ' -in:file:native ' + template + ' -abinitio:steal_3mers True -abinitio:steal_9mers True -abinitio:start_native True -templates:force_native_topology True'


if MakeModels == True:
  PATH_TO_MODELS = RunDir + '/models'
      
  # If we are running with cluster support submit all modelling jobs to the cluster queue
  if CLUSTER:
#      seed_list=[]
      seed_list=[1005621, 1008740, 1011651, 1017014, 1025795, 1031779, 1031884, 1049979, 1053210, 1062457, 1062717, 1066063, 1066472, 1075062, 1083713, 1087066, 1087460, 1091671, 1095542, 1096265, 1097925, 1101557, 1109957, 1130025, 1133220, 1134228, 1134982, 1136591, 1145330, 1156171, 1156397, 1158506, 1162329, 1162998, 1181274, 1190538, 1208819, 1218000, 1220669, 1231294, 1233133, 1233276, 1236758, 1239543, 1243437, 1254097, 1259507, 1266359, 1282714, 1302550, 1309049, 1311679, 1313618, 1314572, 1325530, 1335352, 1338011, 1338113, 1343642, 1349174, 1361411, 1367671, 1377096, 1382749, 1435855, 1465324, 1468638, 1484747, 1515356, 1532548, 1533067, 1533232, 1541998, 1551732, 1552379, 1560268, 1572668, 1584009, 1627853, 1639754, 1658065, 1706136, 1714816, 1720479, 1727407, 1733591, 1754248, 1754342, 1756245, 1766068, 1799070, 1817609, 1824877, 1825988, 1829008, 1830308, 1830611, 1833628, 1836428, 1860308, 1875570, 1890197, 1903686, 1904760, 1917217, 1931705, 1937319, 1937715, 1938352, 1938966, 1949298, 1949437, 1952647, 1959528, 1964922, 1969580, 1977640, 1983732, 1986309, 2002127, 2002320, 2021518, 2025631, 2027207, 2031803, 2041772, 2045045, 2053976, 2058302, 2108118, 2117701, 2118778, 2157654, 2170130, 2170867, 2180936, 2190951, 2192313, 2200074, 2207247, 2218881, 2220627, 2230036, 2235753, 2250958, 2272417, 2296737, 2303035, 2347176, 2351336, 2354130, 2358129, 2364420, 2367375, 2373733, 2382077, 2389684, 2391607, 2425403, 2429599, 2436652, 2438988, 2456810, 2468975, 2491131, 2500208, 2500549, 2518540, 2529096, 2530076, 2542942, 2546016, 2558299, 2567651, 2568799, 2577313, 2582758, 2585324, 2591397, 2593905, 2614952, 2615690, 2617804, 2654273, 2654916, 2658702, 2675150, 2691905, 2696201, 2697011, 2712737, 2717549, 2721821, 2722771, 2727745, 2730983, 2744372, 2760509, 2769001, 2769952, 2789693, 2810043, 2810755, 2811849, 2826832, 2827802, 2827824, 2828167, 2851453, 2853247, 2880261, 2886756, 2892772, 2905432, 2905800, 2906884, 2911839, 2914906, 2937061, 2941567, 2943452, 2968646, 2971086, 2977413, 2982284, 2982663, 3013984, 3028807, 3039119, 3053864, 3062349, 3064589, 3065239, 3072862, 3082068, 3083094, 3083288, 3086918, 3090748, 3103049, 3109863, 3127707, 3128913, 3154659, 3170333, 3170545, 3175696, 3195347, 3200790, 3207876, 3209872, 3221304, 3232520, 3239527, 3265571, 3280041, 3303486, 3304258, 3310470, 3315279, 3326773, 3348554, 3350007, 3357685, 3362211, 3377700, 3384683, 3416205, 3416438, 3420343, 3433361, 3434644, 3457971, 3478526, 3478920, 3500873, 3506182, 3521262, 3527909, 3530235, 3567956, 3573196, 3582974, 3599265, 3603119, 3649027, 3655891, 3663680, 3666223, 3685874, 3705433, 3714528, 3715314, 3716473, 3729988, 3749764, 3751363, 3765355, 3774955, 3807198, 3815042, 3830201, 3873667, 3877320, 3877330, 3882647, 3890054, 3904093, 3904169, 3913383, 3924432, 3947763, 3957044, 4003122, 4033693, 4034132, 4054435, 4058624, 4063011, 4079383, 4083853, 4085048, 4090921, 4098291, 4103250, 4136204, 4139068, 4140298, 4141608, 4142834, 4146538, 4152350, 4159882, 4160469, 4160480, 4166711, 4173966, 4186290, 4198936, 4204954, 4240964, 4259148, 4261832, 4266376, 4275777, 4284482, 4298463, 4300505, 4324370, 4327635, 4349803, 4391076, 4408725, 4421147, 4424703, 4469773, 4485602, 4489114, 4539366, 4540272, 4579712, 4589614, 4590301, 4591806, 4632852, 4641788, 4643440, 4650337, 4651946, 4652621, 4678677, 4684491, 4716462, 4722135, 4727102, 4734073, 4739902, 4751950, 4756795, 4769853, 4778116, 4781739, 4787342, 4790871, 4791369, 4793404, 4810649, 4843028, 4854729, 4876062, 4880456, 4907997, 4918750, 4940784, 4952384, 4955305, 4956930, 4958067, 4959752, 4970110, 4981002, 4983840, 4986512, 4988988, 5002620, 5022665, 5022786, 5026792, 5036674, 5039666, 5040504, 5064310, 5068849, 5080018, 5094655, 5108847, 5136256, 5140190, 5147003, 5169693, 5176491, 5178451, 5185632, 5186095, 5195747, 5202472, 5240021, 5251356, 5254004, 5257310, 5268475, 5281623, 5303149, 5324788, 5329005, 5350463, 5357809, 5389182, 5408636, 5410784, 5415160, 5427129, 5435201, 5460212, 5462135, 5465150, 5467879, 5482086, 5503065, 5503505, 5506300, 5522986, 5537594, 5539127, 5548253, 5564649, 5564889, 5580649, 5580922, 5588840, 5592431, 5600295, 5600386, 5603493, 5619324, 5620769, 5624223, 5650440, 5652737, 5658429, 5658630, 5661249, 5695439, 5705180, 5711021, 5714900, 5731769, 5741723, 5744698, 5756136, 5761697, 5765763, 5793297, 5823926, 5826347, 5827445, 5834088, 5841182, 5844867, 5847306, 5853091, 5868401, 5928612, 5933486, 5941068, 5942446, 5966207, 5972952, 5985775, 5993774] 

      # Generate the list of random seeds
      #while len(seed_list) < NMODELS:
      #  seed=random.randint(1000000, 4000000)
      #  if seed not in seed_list:
      #     seed_list.append(seed)

      # Invoke the cluster run class
      cluster_run=clusterize.ClusterRun()
      cluster_run.QTYPE="SGE"
      cluster_run.ALLATOM=ALLATOM
      cluster_run.setupModellingDir(RunDir)
      cluster_run.setScwrlEXE(SCWRL)
  
      # loop over the number of models and submit a job to the cluster
      for i in range(NMODELS):
        cluster_run.modelOnCluster(RunDir, 1, i+1, ROSETTA_PATH, ROSETTA_DB, FASTA, frags_3_mers, frags_9_mers, seed_list[i], insert_Rosetta_command+CCline)

      # Monitor the cluster queue to see when all jobs have finished
      cluster_run.monitorQueue()

  else:
      previous_seeds = [0]    #make random seeds  (1000000, 6000000) ! Must be unique seeds!!!!
      proc = 1
      while proc < NProc +1:
        new_seed = random.randint(1000000, 4000000)  
        seed_present = False

        for seed in previous_seeds:
           if new_seed == seed:
             seed_present = True
             break

        if seed_present == False:
          previous_seeds.append(new_seed)
          proc +=1

      print previous_seeds

      split_jobs =  NMODELS / NProc   ### split jobs between processors
      remainder =   NMODELS % NProc
      jobs = [0]      
      proc = 1
      while proc < NProc +1:
        jobs.insert(proc, split_jobs)
        proc +=1
      jobs[-1] = jobs[-1] + remainder    
      print jobs  ##################################


 

      os.system('mkdir '+ RunDir +'/models')
      PATH_TO_MODELS = RunDir +'/models'

      proc = 1
      while proc < NProc +1:
       print proc
 
       os.system('mkdir '+ RunDir + '/models_'+str(proc))
       os.chdir(RunDir + '/models_'+str(proc))

       

       if ALLATOM == False:
          RUNNING.write(ROSETTA_PATH +' -database ' + ROSETTA_DB + ' -in::file::fasta ' + FASTA + ' -in:file:frag3 '+ frags_3_mers +' -in:file:frag9 '+ frags_9_mers + ' -out:path ' +RunDir + '/models_'+str(proc)+' -out:pdb -out:nstruct ' + str(jobs[proc]) + ' -out:file:silent '+RunDir +'/models_'+str(proc) +'/OUT -return_full_atom false   -run:constant_seed -run:jran ' + str( previous_seeds[proc]) + insert_Rosetta_command+CCline+' > rosetta_' + str(proc) + '.log  &')
          RUNNING.flush()

          os.system(ROSETTA_PATH +' -database ' + ROSETTA_DB + ' -in::file::fasta ' + FASTA + ' -in:file:frag3 '+ frags_3_mers +' -in:file:frag9 '+ frags_9_mers + ' -out:path ' +RunDir + '/models_'+str(proc)+' -out:pdb -out:nstruct ' + str(jobs[proc]) + ' -out:file:silent '+RunDir +'/models_'+str(proc) +'/OUT -return_full_atom false   -run:constant_seed -run:jran ' + str( previous_seeds[proc]) + insert_Rosetta_command+CCline+' > rosetta_' + str(proc) + '.log  &')

       else:
          RUNNING.write(ROSETTA_PATH +' -database ' + ROSETTA_DB + ' -in::file::fasta ' + FASTA + ' -in:file:frag3 '+ frags_3_mers +' -in:file:frag9 '+ frags_9_mers + ' -out:path ' +RunDir + '/models_'+str(proc)+' -out:pdb -out:nstruct ' + str(jobs[proc]) + ' -out:file:silent '+RunDir +'/models_'+str(proc) +'/OUT -return_full_atom true -abinitio:relax  -run:constant_seed -run:jran ' + str( previous_seeds[proc]) + insert_Rosetta_command+CCline+' > rosetta_' + str(proc) + '.log  &')
          RUNNING.flush()

          os.system(ROSETTA_PATH +' -database ' + ROSETTA_DB + ' -in::file::fasta ' + FASTA + ' -in:file:frag3 '+ frags_3_mers +' -in:file:frag9 '+ frags_9_mers + ' -out:path ' +RunDir + '/models_'+str(proc)+' -out:pdb -out:nstruct ' + str(jobs[proc]) + ' -out:file:silent '+RunDir +'/models_'+str(proc) +'/OUT -return_full_atom true -abinitio:relax   -run:constant_seed -run:jran ' + str( previous_seeds[proc]) + insert_Rosetta_command+CCline+' > rosetta_' + str(proc) + '.log  &')


       proc +=1




### wait for all models to be made, check number for each job

      no_models_to_make = NMODELS
      no_models_have = 0 
      while no_models_have !=  no_models_to_make:
        no_models_have = 0
        proc = 1
        while proc < NProc +1:
          list_of_files = [file for file in os.listdir(RunDir +'/models_'+str(proc) ) if file.lower().endswith('.pdb')]


          no_models_have  += len(list_of_files)
          proc+=1
        print 'Number of models made so far = ' + str(no_models_have)
        if no_models_have ==  no_models_to_make:
           break
        time.sleep(5)       
   
     
   

      
   
      LOG = open(RunDir+'/LOG', "a")
      print 'MODELLING DONE'
## got them all   Must Delete Models or job will hang -----------



      MODELLING_time_stop=time.time()
      cat_string = ''

     # RunDir +'/models'
      proc = 1
      while proc < NProc +1:
         print proc
         
         add_sidechains_SCWRL(SCWRL,   RunDir + '/models_'+str(proc),   RunDir + '/models',  str(proc) )
         cat_string += RunDir + '/OUT_' + str(proc) +'  '
         #os.system('rm -r '+RunDir + '/models_'+str(proc) )
         proc+=1
    
      os.chdir(RunDir)
      print '\n' +cat_string


     ####### keep or delete run files
if MakeModels == False:
  PATH_TO_MODELS = MODELS_LOCATION
RUNNING.write('\n\nModelling done\nmodels at '+PATH_TO_MODELS+'\n\n')

#--------------------------------------------
#check if models are present regardless
#--------------------------------------------


#--------------------------------------
# Do the clustering  
#---------------------------------------
if ENSEMBLE_import ==False:

 if USE_SPICKER==False:
    noClusters=1

    levels = [20,25,30,40,50,60]   # clustering levels
    if NMODELS > 1000:
     levels = [20,25,30,40,50,60,70,80,90,95] 

    print '----------CLUSTERING---------'
    RUNNING.write('----------CLUSTERING---------\n')
    RUNNING.write('Default clustering to find only the largest cluster (see developemnt version for alternate clustering methods)')
    RUNNING.flush()
    cluster_path = RunDir + '/clusters/'  # outpath for clusters
    os.system('mkdir '+ RunDir + '/clusters')



    cluster_results = cluster_entropy.RUN_CLUSTER(levels, PATH_TO_MODELS, LGA, cluster_path,  NProc, NMODELS)


    print 'Clustering Done!'
    RUNNING.write('Clustering Done! your results:\n')
    i = 0
    while i < len(cluster_results):
     RUNNING.write('at level ' +str(levels[i]) + ' cluster size is ' + str(cluster_results[i])+'\n' )
     i+=1
    RUNNING.flush()


#----------------------------------------
#pick a clustering level
#----------------------------------------
#  default method of picking a cluster  cutoffs <50 >5:



    trunc_level = 'nan'
    print levels, cluster_results
    i = 0
    while i < len(cluster_results):
     if  cluster_results[i] <50 and cluster_results[i] >2:
      trunc_level = levels[i]
      break
     i+=1
    print trunc_level


#if none exist in range, go higher:
    if trunc_level == 'nan':
      i = 0
      while i < len(cluster_results):
        if  cluster_results[i] >2 :
          trunc_level = levels[i]
        i+=1

    print trunc_level

#-------------------------------------
#Truncate
#-------------------------------------
    RUNNING.write('\n----------Truncating---------\n')
    RUNNING.flush()
    os.system('mkdir '+RunDir+'/fine')
    os.chdir( RunDir+'/fine')
    models_path = RunDir + '/clusters/cluster_'+str(trunc_level)+'/sorted_cluster_0'

    print THESEUS, models_path, RunDir+'/fine', ROSETTA_cluster 

    Strict= False #  Default = True
    if Strict== True:
     list_of_ensembles = truncateedit.truncate(THESEUS, models_path, RunDir+'/fine', ROSETTA_cluster, ROSETTA_DB )
    if Strict== False:
      
      list_of_ensembles = truncateedit_MAX.truncate(THESEUS, models_path, RunDir+'/fine', MAX, percent, FIXED_INTERVALS )

    RUNNING.write('Truncating done!\n')
    RUNNING.flush()

#-------------------------------------
#fix sidechains
#------------------------------------
    os.system('mkdir '+RunDir+'/ensembles')
    for each_ens in list_of_ensembles:
     SCWRL_edit.edit_sidechains(each_ens, RunDir+'/ensembles/')

    final_ensembles =[]
    for infile in glob.glob( os.path.join(RunDir+'/ensembles', '*.pdb') ):
      final_ensembles.append(infile)

#-------------------------------------
# Spicker Alternative for clustering then MAX 
#------------------------------------
 if USE_SPICKER==True:
    #noClusters=1
    run_spicker.RUN_SPICKER(PATH_TO_MODELS, RunDir+'/spicker_run', SPICKEREXE, int(noClusters) , RunDir )
   
    samples = 1
    while samples < int(noClusters)+1:
      models_path = RunDir + '/S_clusters/cluster_'+str(samples)

      if not os.path.exists(RunDir+'/fine_cluster_'+str(samples)):
         os.mkdir(RunDir+'/fine_cluster_'+str(samples))

      os.chdir(RunDir+'/fine_cluster_'+str(samples) )    
      list_of_ensembles = truncateedit_MAX.truncate(THESEUS, models_path, RunDir+'/fine_cluster_'+str(samples), MAX, percent, FIXED_INTERVALS  )

      os.system('mkdir '+RunDir+'/ensembles_'+str(samples))
      for each_ens in list_of_ensembles:
        SCWRL_edit.edit_sidechains(each_ens, RunDir+'/ensembles_'+str(samples)+'/')

      final_ensembles =[]
      for infile in glob.glob( os.path.join(RunDir+'/ensembles_'+str(samples), '*.pdb') ):
         final_ensembles.append(infile)



      bump_dir = os.path.join(RunDir, 'MRBUMP')
      if not os.path.exists(bump_dir):
       os.mkdir(bump_dir)
      os.chdir(bump_dir)
      if MISSING_DOMAINS == False:
         if CLUSTER:
            sys.stdout.write("Running MR and model building on a cluster\n\n")
   
            mrBuild=clusterize.ClusterRun()
            mrBuild.QTYPE="SGE"
   
            mrBuildClusterDir=os.path.join(bump_dir, "cluster_run"+str(samples))
            os.mkdir(mrBuildClusterDir)
   
            mrBuild.HKLIN = MTZ
            mrBuild.LABIN["F"]         = flag_F
            mrBuild.LABIN["SIGF"]      = flag_SIGF
            mrBuild.LABIN["FreeR_flag"] = flag_FREE
            mrBuild.SEQIN = FASTA
            mrBuild.getMTZInfo(mrBuild.HKLIN, mrBuildClusterDir)
   
            # Reset the queue list
            mrBuild.qList=[]
            jobID=0
            for pdbfile in final_ensembles:
               mrBuild.mrBuildOnCluster(mrBuildClusterDir, pdbfile, jobID)
               jobID=jobID+1
            mrBuild.monitorQueue()

            #cleanup
            for each_run in os.listdir(mrBuildClusterDir ):
               if os.path.isdir(  os.path.join(mrBuildClusterDir, each_run)):
                  name=re.split('_', each_run)
                  mrBuildOutputDir=os.path.join(bump_dir, "cluster_run"+str(samples)+"result"+name[1]) 
                  os.mkdir(mrBuildOutputDir)                   
                  shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","phaser_shelx" ),mrBuildOutputDir  )
                  shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","molrep_shelx" ),mrBuildOutputDir  )  
                  shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","data" ),mrBuildOutputDir  )               
            shutil.rmtree(mrBuildClusterDir)
   
      # Monitor the cluster queue to see when all jobs have finished

          
         if not CLUSTER: 
            bump_dir = os.path.join(RunDir, 'MRBUMP_cluster'+str(samples))
            os.mkdir(bump_dir) 
            os.chdir(bump_dir)
            split_ensembles = run_mr_bump_shelx_parallel.split(final_ensembles, NProc)
            run_mr_bump_shelx_parallel.split_into_runs(MTZ, split_ensembles, bump_dir, FASTA, NProc, flag_SIGF, flag_F, flag_FREE, noASU)
            Final_display_results.make_log(bump_dir, RunDir+'/Final_results.log')



      if MISSING_DOMAINS == True:
        if  CLUSTER:
            print 'this needs to be added'
# --------------- missing domains cluster

      if MISSING_DOMAINS == True:
        if  CLUSTER:
            sys.stdout.write("Running MR and model building on a cluster\n\n")
   
            mrBuild=clusterize.ClusterRun()
            mrBuild.QTYPE="SGE"
   
            mrBuildClusterDir=os.path.join(bump_dir, "cluster_run"+str(samples))
            os.mkdir(mrBuildClusterDir)
   

            mrBuild.HKLIN = MTZ
            mrBuild.LABIN["F"]         = flag_F
            mrBuild.LABIN["SIGF"]      = flag_SIGF
            mrBuild.LABIN["FreeR_flag"] = flag_FREE
            mrBuild.SEQIN = domain_all_chain_fasta
            mrBuild.getMTZInfo(mrBuild.HKLIN, mrBuildClusterDir)

#            mrBuild.FIXEDIN='FIXED_XYZIN '+domain_all_chains_pdb+' IDENTIY 0.6 \n'

            # Reset the queue list
            mrBuild.qList=[]
            jobID=0
            for pdbfile in final_ensembles:
               mrBuild.mrBuildOnCluster(mrBuildClusterDir, pdbfile, jobID ,  domain_all_chains_pdb , '0.6')
               jobID=jobID+1
            mrBuild.monitorQueue()

            #cleanup
            for each_run in os.listdir(mrBuildClusterDir ):
               if os.path.isdir(  os.path.join(mrBuildClusterDir, each_run)):
                  name=re.split('_', each_run)
                  mrBuildOutputDir=os.path.join(bump_dir, "cluster_run"+str(samples)+"result"+name[1]) 
                  os.mkdir(mrBuildOutputDir)                   
                  shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","phaser_shelx" ),mrBuildOutputDir  )
                  shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","molrep_shelx" ),mrBuildOutputDir  )  
                  shutil.move (os.path.join(mrBuildClusterDir, each_run, "search_"+name[1]+"_mrbump","data" ),mrBuildOutputDir  )               
            shutil.rmtree(mrBuildClusterDir)
   
#-------------------------------------
        else:
         print domain_all_chains_pdb
         print domain_all_chain_fasta
         bump_dir = os.path.join(RunDir, 'MRBUMP_cluster'+str(samples))
         os.mkdir(bump_dir) 
         os.chdir(bump_dir)
         split_ensembles = run_mr_bump_shelx_parallel.split(final_ensembles, NProc)
         run_mr_bump_shelx_parallel.split_into_runs_domains(MTZ, split_ensembles, bump_dir, domain_all_chain_fasta , NProc, domain_all_chains_pdb)
         Final_display_results.make_log(bump_dir, RunDir+'/Final_results.log')


      samples+=1


    time_stop=time.time()
    elapsed_time= time_stop - time_start
    run_in_min=elapsed_time/60
    run_in_hours = run_in_min/60

    RUNNING.write('\nMR and shelx ALL DONE  (in '+str(run_in_hours)+' hours) \n----------------------------------------\n')
    RUNNING.flush()
    RUNNING.close()

    os.system('tar -cvf '+PDB_code+'_' + RunDir+'.tar '+RunDir)
    os.system('gzip ' +PDB_code+'_'+ RunDir+'.tar')
    os.system('mv '+ PDB_code+'_'+  RunDir+'.tar.gz /data2/jac45 ')
    os.system('rm '+RunDir)
    #stop here
    sys.exit()



#------------------------------------
# END
#----------------------------------
time_stop=time.time()

elapsed_time= time_stop - time_start
run_in_min=elapsed_time/60
run_in_hours = run_in_min/60

RUNNING.write('\nMODELLING and ASSEMBLY ALL DONE  (in '+str(run_in_hours)+' hours) \n----------------------------------------\n')
RUNNING.flush()

if ENSEMBLE_import ==True:
 final_ensembles =[]
 for infile in glob.glob( os.path.join(ENSEMBLES, '*.pdb') ):
   final_ensembles.append(infile)

#--------------Import into MrBUMP here-------------------
RUNNING.write('Running MrBUMP\nMR LOGS in '+RunDir+'/MRBUMP')
RUNNING.flush()

#os.system('mkdir ' + RunDir+'/MRBUMP')
bump_dir = os.path.join(RunDir, 'MRBUMP')
os.mkdir(bump_dir)
os.chdir(bump_dir)

if MISSING_DOMAINS == False:
   if CLUSTER:
      sys.stdout.write("Running MR and model building on a cluster\n\n")
   
      mrBuild=clusterize.ClusterRun()
      mrBuild.QTYPE="SGE"
   
      mrBuildClusterDir=os.path.join(bump_dir, "cluster_run")
      os.mkdir(mrBuildClusterDir)
   
      mrBuild.HKLIN = MTZ
      mrBuild.LABIN["F"]         = flag_F
      mrBuild.LABIN["SIGF"]      = flag_SIGF
      mrBuild.LABIN["FreeR_flag"] = flag_FREE
      mrBuild.SEQIN = FASTA
      mrBuild.getMTZInfo(mrBuild.HKLIN, mrBuildClusterDir)
   
      # Reset the queue list
      mrBuild.qList=[]
      jobID=0
      for pdbfile in final_ensembles:
         mrBuild.mrBuildOnCluster(mrBuildClusterDir, pdbfile, jobID)
         jobID=jobID+1




      # Monitor the cluster queue to see when all jobs have finished
      mrBuild.monitorQueue()
   else: 
      split_ensembles = run_mr_bump_shelx_parallel.split(final_ensembles, NProc)
      run_mr_bump_shelx_parallel.split_into_runs(MTZ, split_ensembles, bump_dir, FASTA, NProc, flag_SIGF, flag_F, flag_FREE, noASU)
      Final_display_results.make_log(bump_dir, RunDir+'/Final_results.log')

if MISSING_DOMAINS == True:
  if  CLUSTER:

      sys.stdout.write("Running MR and model building on a cluster\n\n")
   
      mrBuild=clusterize.ClusterRun()
      mrBuild.QTYPE="SGE"
   
      mrBuildClusterDir=os.path.join(bump_dir, "cluster_run")
      os.mkdir(mrBuildClusterDir)
   
      mrBuild.HKLIN = MTZ
      mrBuild.LABIN["F"]         = flag_F
      mrBuild.LABIN["SIGF"]      = flag_SIGF
      mrBuild.LABIN["FreeR_flag"] = flag_FREE
      mrBuild.SEQIN = domain_all_chain_fasta
      mrBuild.getMTZInfo(mrBuild.HKLIN, mrBuildClusterDir)
   
      # Reset the queue list
      mrBuild.qList=[]
      jobID=0
      for pdbfile in final_ensembles:
         mrBuild.mrBuildOnCluster(mrBuildClusterDir, pdbfile, jobID, domain_all_chains_pdb, 0.6)
         jobID=jobID+1



  else:
   print domain_all_chains_pdb
   print domain_all_chain_fasta
   print 'the input is fixed ', FIXED_INPUT


   split_ensembles = run_mr_bump_shelx_parallel.split(final_ensembles, NProc)
   run_mr_bump_shelx_parallel.split_into_runs_domains(MTZ, split_ensembles, bump_dir, domain_all_chain_fasta , NProc, domain_all_chains_pdb, FIXED_INPUT)
   Final_display_results.make_log(bump_dir, RunDir+'/Final_results.log')




time_stop=time.time()
elapsed_time= time_stop - time_start
run_in_min=elapsed_time/60
run_in_hours = run_in_min/60

RUNNING.write('\nMR and shelx ALL DONE  (in '+str(run_in_hours)+' hours) \n----------------------------------------\n')
RUNNING.flush()

